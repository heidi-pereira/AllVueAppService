-- FULL Deployment script generated by Snowflake DevOps Tools
-- All changes in dependency order, scripts inlined

create transient schema if not exists impl_result;
create transient schema if not exists impl_weight;
create schema if not exists raw;
create transient schema if not exists impl_response_set;
create transient schema if not exists impl_survey;
create transient schema if not exists impl_sub_product;
create transient schema if not exists client_all__response_set;
create transient schema if not exists impl_response_set_unconfigured;
create or replace transient schema savanta_internal__utils;

-- Deploying: schemas\raw\tables\response_set_role_mappings.sql
create or alter table raw.response_set_role_mappings (
    -- Manual override table to give permission. Main long term use expected to be client data shares
    -- Can use internally until we have Entra/Kimble integrations
    response_set_id number(38, 0) not null,
    role_name varchar(256) not null,
    primary key (response_set_id, role_name)
);


-- Deploying: schemas\impl_weight\tables\_cell_definitions.sql
create or alter transient table impl_weight._cell_definitions (
    response_set_id integer,
    root_weighting_plan_id integer,
    cell_id integer,
    target_weight number(20, 10),
    weighting_parts variant
);


-- Deploying: schemas\impl_survey\tables\choice_set_root_ancestors.sql
create or alter transient table impl_survey.choice_set_root_ancestors (
    survey_id int not null,
    choice_set_id int not null,
    root_ancestor_id int not null,
    generation int not null
)
change_tracking = true;


-- Deploying: schemas\impl_result\tables\_integers.sql
create or replace transient table impl_result._integers (number int)
as
select row_number() over (order by 0) as number
from table(generator(rowcount => 10000));


-- Deploying: schemas\impl_response_set_unconfigured\tables\canonical_choice_set_alternative_mappings.sql
create or alter transient table impl_response_set_unconfigured.canonical_choice_set_alternative_mappings (
    response_set_id number(10, 0),
    canonical_choice_set_id number(10, 0),
    alternative_choice_set_id number(10, 0)
)
change_tracking = true;


-- Deploying: schemas\impl_response_set\tables\_checked_choices.sql
create or replace transient table impl_response_set._checked_choices as (
    --This can't be inlined in a dynamic table sadly
    select column1 as entity_instance_id, column2 as name
    from values (0, 'Unchecked'), (1, 'Checked')
);


-- Deploying: schemas\impl_survey\tables\all_questions_including_confidential.sql
create or replace transient dynamic table impl_survey.all_questions_including_confidential (
    var_code varchar(256),
    question_id integer,
    survey_id integer,
    question_text varchar(2000),
    is_confidential boolean,
    is_multiple_choice boolean,
    min_value integer,
    max_value integer,
    item_number integer,
    number_format varchar(256),
    opaque_question_layout_signature integer comment 'Opaque value. When different, the data layout is definitely not compatible. When the same it is the same shape. i.e. choice sets in the same slots'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        q.var_code,
        q.question_id,
        q.survey_id,
        q.question_text,
        q.is_confidential,
        case when q.master_type = 'CHECKBOX' then true else false end as is_multiple_choice,
        case
            when q.answer_choice_set_id is null and q.master_type != 'CHECKBOX' and q.minimum_value < q.maximum_value
                then q.minimum_value
            else null
        end as min_value,
        case
            when q.answer_choice_set_id is null and q.master_type != 'CHECKBOX' and q.minimum_value < q.maximum_value
                then q.maximum_value
            else null
        end as max_value,
        q.item_number,
        q.number_format,
        -- Must precisely match logic in impl_sub_product.variable_configurations.opaque_question_layout_signature
        (
            iff(q.section_choice_set_id is not null, bit_shiftleft(1, 3), 0) +
            iff(q.page_choice_set_id is not null, bit_shiftleft(1, 2), 0) +
            iff(q.question_choice_set_id is not null, bit_shiftleft(1, 1), 0) +
            iff(q.answer_choice_set_id is not null, bit_shiftleft(1, 0), 0)
        ) as opaque_question_layout_signature
    from raw_survey.all_questions_including_confidential q
);


-- Deploying: schemas\impl_survey\streams\_choice_set_root_ancestors_choice_sets_stream.sql
create or replace stream impl_survey._choice_set_root_ancestors_choice_sets_stream on table raw_survey.choice_sets;


-- Deploying: schemas\impl_sub_product\tables\sub_products.sql
create or replace transient dynamic table impl_sub_product.sub_products (
    sub_product_id integer,
    product_identifier varchar(256),
    sub_product_unqualified_identifier varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        -- synthesise a stable-ish gobally unique integer for easy joining
        min(sc.id) as sub_product_id,
        sc.product_short_code as product_identifier,
        sc.sub_product_id as sub_product_unqualified_identifier
    from raw_config.subset_configurations sc
    where not sc.disabled
    group by product_identifier, sub_product_unqualified_identifier
);


-- Deploying: schemas\impl_response_set\tables\response_set_role_mappings.sql
create or replace dynamic table impl_response_set.response_set_role_mappings (
    response_set_id integer not null,
    role_name string not null
) cluster by (response_set_id, role_name)
target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- Use this table to join in other sources such as kimble or entra, so that the policy functions stays as a simple lookup.
    -- We may end up needing a similar table for response_set_user_mappings if we can't manage to map roles appropriately.
    select
        response_set_id,
        role_name
    from raw.response_set_role_mappings
);


-- Deploying: schemas\impl_weight\tables\_cell_variable_mappings.sql
create or replace transient dynamic table impl_weight._cell_variable_mappings (
    response_set_id integer,
    root_weighting_plan_id integer,
    cell_id integer,
    variable_identifier varchar(16777216),
    entity_instance_id integer,
    num_required_parts integer,
    target_weight float
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    --flatten variant into rows
    select
        cd.response_set_id,
        cd.root_weighting_plan_id,
        cd.cell_id,
        f.key as variable_identifier,
        f.value::number as entity_instance_id,
        array_size(object_keys(cd.weighting_parts)) as num_required_parts,
        cd.target_weight
    from impl_weight._cell_definitions cd,
        lateral flatten(input => cd.weighting_parts) f
);


-- Deploying: schemas\impl_survey\procedures\update_choice_set_root_ancestors.sql
create or replace procedure impl_survey.update_choice_set_root_ancestors(survey_ids array)
returns string
language sql
as
begin
    -- Early exit if survey_ids array is empty
    if (array_size(:survey_ids) = 0) then
        return 'done';
    end if;

    create or replace temporary table impl_survey.__temp_surveys_to_update (survey_id_to_update int) as
    select distinct to_number(value) as survey_id_to_update
    from table(flatten(input => :survey_ids));

    delete from impl_survey.choice_set_root_ancestors
    where survey_id in (select stu.survey_id_to_update from impl_survey.__temp_surveys_to_update stu);

    create or replace temporary table impl_survey.__temp_choice_set_root_ancestors as
    select distinct
        cs.survey_id,
        cs.choice_set_id,
        connect_by_root(cs.choice_set_id) as root_ancestor_id,
        level as generation
    from raw_survey.choice_sets cs
    join impl_survey.__temp_surveys_to_update stu
        on cs.survey_id = stu.survey_id_to_update
    start with cs.parent_choice_set1_id is null
        and cs.parent_choice_set2_id is null
    connect by cs.parent_choice_set1_id = prior cs.choice_set_id
        or cs.parent_choice_set2_id = prior cs.choice_set_id;

    delete from impl_survey.choice_set_root_ancestors
    where survey_id in (select stu.survey_id_to_update from impl_survey.__temp_surveys_to_update stu);

    insert into impl_survey.choice_set_root_ancestors (survey_id, choice_set_id, root_ancestor_id, generation)
    select survey_id, choice_set_id, root_ancestor_id, generation
    from impl_survey.__temp_choice_set_root_ancestors;

    drop table if exists impl_survey.__temp_choice_set_root_ancestors;
    drop table if exists impl_survey.__temp_surveys_to_update;

    return 'done';
end;


-- Deploying: schemas\impl_survey\tables\canonical_choice_set_alternative_mappings.sql
create or replace transient dynamic table impl_survey.canonical_choice_set_alternative_mappings (
    root_ancestor_ids_sorted array,
    canonical_choice_set_id integer,
    alternative_choice_set_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with choice_set_ancestors_array as (
        select
            cs.choice_set_id,
            max(generation) as generation,
            array_sort(array_agg(distinct root_ancestor_id))
                as root_ancestor_ids_sorted
        from raw_survey.choice_sets cs
        join
            impl_survey.choice_set_root_ancestors csra
            on cs.choice_set_id = csra.choice_set_id
        group by cs.choice_set_id
    )

    select
        csaa.root_ancestor_ids_sorted,
        first_value(csaa.choice_set_id) over (
            partition by csaa.root_ancestor_ids_sorted
            order by csaa.generation, csaa.choice_set_id
        ) as canonical_choice_set_id,
        csaa.choice_set_id as alternative_choice_set_id
    from choice_set_ancestors_array csaa
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\canonical_choices.sql
create or replace transient dynamic table impl_response_set_unconfigured.canonical_choices (
    response_set_id integer,
    canonical_choice_set_id integer,
    survey_choice_id integer,
    display_name varchar(2000),
    latest_survey_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select distinct
        csm.response_set_id,
        csm.canonical_choice_set_id,
        c.survey_choice_id,
        -- Always want the choice display text from the latest survey to stay with the times
        first_value(c.name)
            over (
                partition by
                    csm.response_set_id,
                    csm.canonical_choice_set_id,
                    c.survey_choice_id
                order by c.survey_id desc
            )
            as display_name,
        first_value(c.survey_id)
            over (
                partition by
                    csm.response_set_id,
                    csm.canonical_choice_set_id,
                    c.survey_choice_id
                order by c.survey_id desc
            ) as latest_survey_id
    from impl_response_set_unconfigured.canonical_choice_set_alternative_mappings csm
    join raw_survey.choices c
        on csm.alternative_choice_set_id = c.choice_set_id
);


-- Deploying: schemas\impl_sub_product\tables\entity_instance_configurations.sql
create or replace transient dynamic table impl_sub_product.entity_instance_configurations (
    entity_type_identifier varchar(256),
    entity_instance_id integer,
    display_name_override_by_subset variant,
    enabled_by_subset variant,
    start_date_by_subset variant,
    sub_product_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        eic.entity_type_identifier,
        eic.survey_choice_id as entity_instance_id,
        eic.display_name_override_by_subset::variant,
        eic.enabled_by_subset::variant,
        eic.start_date_by_subset::variant,
        sp.sub_product_id
    from raw_config.entity_instance_configurations eic
    inner join impl_sub_product.sub_products sp
        on
            sp.product_identifier = eic.product_short_code
            and sp.sub_product_unqualified_identifier is not distinct from eic.sub_product_id
    where entity_instance_id is not null
);


-- Deploying: schemas\impl_sub_product\tables\variable_configurations.sql
create or replace transient dynamic table impl_sub_product.variable_configurations (
    sub_product_id integer,
    variable_configuration_id integer,
    variable_identifier varchar(256),
    definition variant,
    display_name varchar(256),
    -- Only set for questions for now - will one day be set for all: https://app.shortcut.com/mig-global/story/98191/store-cached-variableexpression-in-db
    asked_entity_type_identifier_1 varchar(256),
    asked_entity_type_identifier_2 varchar(256),
    asked_entity_type_identifier_3 varchar(256),
    answer_entity_type_identifier varchar(256),
    question_var_code varchar(256) comment 'Original survey var code - only set for questions',
    opaque_question_layout_signature integer comment 'Opaque value. When different, the data layout is definitely not compatible. When the same it is the same shape. i.e. choice sets in the same slots'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with cte as (
        select
            vc.id as variable_configuration_id,
            array_construct_compact(
                max(case when f.value:"Item1" = 'SectionChoiceId' then f.value:"Item2" end),
                max(case when f.value:"Item1" = 'PageChoiceId' then f.value:"Item2" end),
                max(case when f.value:"Item1" = 'QuestionChoiceId' then f.value:"Item2" end)
            ) as asked_array,
            max(case when f.value:"Item1" = 'AnswerChoiceId' then f.value:"Item2" end) as answer_entity_type_identifier,
            -- Must precisely match logic in impl_response_set.questions.opaque_question_layout_signature
            (
                max(iff(f.value:"Item1" = 'SectionChoiceId', bit_shiftleft(1, 3), 0))
                + max(iff(f.value:"Item1" = 'PageChoiceId', bit_shiftleft(1, 2), 0))
                + max(iff(f.value:"Item1" = 'QuestionChoiceId', bit_shiftleft(1, 1), 0))
                + max(iff(f.value:"Item1" = 'AnswerChoiceId', bit_shiftleft(1, 0), 0))
            ) as opaque_question_layout_signature
        from raw_config.variable_configurations vc
        left join lateral flatten(input => parse_json(vc.definition):EntityTypeNames) f
        group by vc.id
    )

    select
        sp.sub_product_id,
        vc.id as variable_configuration_id,
        vc.identifier as variable_identifier,
        vc.definition,
        vc.display_name,
        cte.asked_array[0] as asked_entity_type_identifier_1,
        cte.asked_array[1] as asked_entity_type_identifier_2,
        cte.asked_array[2] as asked_entity_type_identifier_3,
        cte.answer_entity_type_identifier,
        vc.definition:"QuestionVarCode" as question_var_code,
        cte.opaque_question_layout_signature
    from raw_config.variable_configurations vc
    join impl_sub_product.sub_products sp
        on
            vc.product_short_code = sp.product_identifier
            and vc.sub_product_id is not distinct from sp.sub_product_unqualified_identifier
    left join cte on vc.id = cte.variable_configuration_id
);


-- Deploying: schemas\impl_response_set\tables\response_sets.sql
create or replace transient dynamic table impl_response_set.response_sets (
    response_set_id integer not null,
    response_set_identifier varchar(256) not null,
    qualified_response_set_descriptor varchar(512) not null,
    auth_company_id varchar(36) not null,
    is_savanta boolean not null,
    display_name varchar(256) not null,
    sub_product_id integer not null,
    parent_group_name varchar(256) not null,
    full_display_name varchar(512) not null,
    survey_ids array not null,
    survey_id_to_allowed_segment_names variant not null,
    first_survey_id integer not null,
    first_survey_name varchar(100) not null,
    start_date timestamp_ntz(3) not null,
    end_date timestamp_ntz(3),
    kimble_proposal_ids array not null,
    security_group_ids array not null
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with subsets as (
        select
            sc.id as response_set_id,
            coalesce(sc.alias, sc.identifier) as response_set_identifier,
            sc.display_name,
            sp.sub_product_id,
            sc.parent_group_name,
            lower(
                regexp_replace(
                    lower(
                        coalesce(sp.sub_product_unqualified_identifier, iff(sp.product_identifier = 'brandvue', 'brandvue', 'brandvue_' || sp.product_identifier))
                        || '_' ||
                        case
                            -- BrandVue 360 was accidentally setup with the parent group name "US" as a prefix to the id.
                            -- Putting it as a suffix makes all the brandvues look consistent.
                            when
                                len(sc.parent_group_name) > 0
                                and (coalesce(sc.alias, sc.identifier) ilike sc.parent_group_name || '-%')
                                then
                                    regexp_replace(coalesce(sc.alias, sc.identifier), '^' || sc.parent_group_name || '-(.*)$', '\\1')
                                    || '_' || sc.parent_group_name
                            else
                                coalesce(sc.alias, sc.identifier)
                        end
                    ),
                    '[^\\w]', '_'
                )
            ) as qualified_response_set_descriptor,
            regexp_replace(coalesce(sp.sub_product_unqualified_identifier, sp.product_identifier), '[^\\w]', ' ')
            || ' ' || sc.display_name || iff(sc.parent_group_name is not null, ' ' || sc.parent_group_name, '') as full_display_name,
            transform(
                object_keys(survey_id_to_allowed_segment_names),
                id string -> id::int
            ) as survey_ids,
            survey_id_to_allowed_segment_names::variant
                as survey_id_to_allowed_segment_names
        from raw_config.subset_configurations sc
        inner join impl_sub_product.sub_products sp
            on
                sp.product_identifier = sc.product_short_code
                and sp.sub_product_unqualified_identifier is not distinct from sc.sub_product_id
        where not sc.disabled
    ),

    subsets_with_survey_details as (
        select distinct
            subsets.response_set_id,
            min(s.auth_company_id) over (partition by subsets.response_set_id) as min_auth_company_id,
            max(s.auth_company_id) over (partition by subsets.response_set_id) as max_auth_company_id,
            min(auth_company_id ilike '5aab7fae-2720-464b-b2e9-4c3c533d9ff7') over (partition by subsets.response_set_id) as is_savanta,
            first_value(s.survey_id) over (partition by subsets.response_set_id order by s.survey_id) as first_survey_id,
            first_value(s.name) over (partition by subsets.response_set_id order by s.survey_id) as first_survey_name,
            min(s.start_date) over (partition by subsets.response_set_id) as start_date,
            max(s.end_date) over (partition by subsets.response_set_id) as end_date,
            array_agg(s.kimble_proposal_id) over (partition by subsets.response_set_id order by s.survey_id) as kimble_proposal_ids,
            array_agg(o.security_group) over (partition by subsets.response_set_id order by s.survey_id) as security_group_ids,
            subsets.response_set_identifier,
            subsets.display_name,
            subsets.sub_product_id,
            subsets.parent_group_name,
            subsets.qualified_response_set_descriptor,
            subsets.full_display_name,
            subsets.survey_ids,
            subsets.survey_id_to_allowed_segment_names
        from subsets
        inner join raw_survey.surveys s on array_contains(s.survey_id, subsets.survey_ids)
        inner join raw_auth.organisations o on o.id ilike s.auth_company_id
    )

    select
        response_set_id,
        response_set_identifier,
        qualified_response_set_descriptor,
        min_auth_company_id as auth_company_id,
        is_savanta,
        display_name,
        sub_product_id,
        parent_group_name,
        full_display_name,
        survey_ids,
        survey_id_to_allowed_segment_names,
        first_survey_id,
        first_survey_name,
        start_date,
        end_date,
        array_distinct(kimble_proposal_ids) as kimble_proposal_ids,
        array_distinct(security_group_ids) as security_group_ids
    from subsets_with_survey_details
    where
        min_auth_company_id = max_auth_company_id and array_size(security_group_ids) = 0
);


-- Deploying: schemas\impl_survey\tasks\incremental_update_survey_choice_set_root_ancestors.sql
create or replace task impl_survey.incremental_update_survey_choice_set_root_ancestors
    -- todo: decide whether this should be in warehouse or serverless. probably best to bound cost by using warehouse that's on anyway
    --target_completion_interval='1 MINUTE'
    warehouse = warehouse_xsmall
when
    system$stream_has_data ('impl_survey._choice_set_root_ancestors_choice_sets_stream')
as begin
    call impl_survey.update_choice_set_root_ancestors(
        select array_agg(distinct survey_id)
        from impl_survey._choice_set_root_ancestors_choice_sets_stream
        where metadata$action in ('INSERT', 'UPDATE', 'DELETE')
    );
end;


-- Deploying: schemas\impl_survey\tables\canonical_choice_set_locations.sql
create or replace transient dynamic table impl_survey.canonical_choice_set_locations (
    question_id integer,
    canonical_choice_set_id integer,
    choice_source varchar(256),
    index integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with all_question_choice_set_locations as (
        select
            q.question_id,
            f.value:choice_set_id::int as choice_set_id,
            f.value:type::string as choice_source,
            f.index
        from raw_survey.all_questions_including_confidential q,
            lateral flatten(input => array_construct_compact(
                case
                    when
                        q.section_choice_set_id is not null
                        then
                            object_construct(
                                'type',
                                'SectionChoiceId',
                                'choice_set_id',
                                q.section_choice_set_id
                            )
                end,
                case
                    when
                        q.page_choice_set_id is not null
                        then
                            object_construct(
                                'type',
                                'PageChoiceId',
                                'choice_set_id',
                                q.page_choice_set_id
                            )
                end,
                case
                    when
                        q.question_choice_set_id is not null
                        then
                            object_construct(
                                'type',
                                'QuestionChoiceId',
                                'choice_set_id',
                                q.question_choice_set_id
                            )
                end,
                case
                    when
                        q.answer_choice_set_id is not null
                        then
                            object_construct(
                                'type',
                                'AnswerChoiceId',
                                'choice_set_id',
                                q.answer_choice_set_id
                            )
                end
            )) f
        where f.value:choice_set_id is not null
    )

    select
        qcs.question_id,
        ccs.canonical_choice_set_id,
        qcs.choice_source,
        qcs.index
    from all_question_choice_set_locations qcs
    join
        impl_survey.canonical_choice_set_alternative_mappings ccs
        on qcs.choice_set_id = ccs.alternative_choice_set_id
);


-- Deploying: schemas\impl_weight\tables\_hardcoded_response_set_cell_definitions.sql
-- response_set_cell_definitions: defines cell parts and ranges for each response set
create or alter transient table impl_weight._hardcoded_response_set_cell_definitions (
    response_set_id number(38, 0) not null,
    cell_part number(38, 0) not null,
    cell_part_id number(38, 0) not null,
    min_value number(38, 0) not null,
    max_value number(38, 0) not null,
    variable_identifier varchar(50) not null
) change_tracking = true;


insert into impl_weight._hardcoded_response_set_cell_definitions (response_set_id, cell_part, cell_part_id, min_value, max_value, variable_identifier)
select rs.response_set_id, eating_out_us_cell_definitions.cell_part, eating_out_us_cell_definitions.cell_part_id, eating_out_us_cell_definitions.min_value, eating_out_us_cell_definitions.max_value, eating_out_us_cell_definitions.variable_identifier from impl_response_set.response_sets rs
inner join impl_sub_product.sub_products sp on sp.sub_product_id = rs.sub_product_id
cross join
    (
        -- west
        select column1 as cell_part, column2 as cell_part_id, column3 as min_value, column4 as max_value, column5 as variable_identifier
        from
            values
            (0, 0, 2, 3, 'US_state'),
            (0, 0, 5, 6, 'US_state'),
            (0, 0, 12, 13, 'US_state'),
            (0, 0, 27, 27, 'US_state'),
            (0, 0, 29, 29, 'US_state'),
            (0, 0, 32, 32, 'US_state'),
            (0, 0, 38, 38, 'US_state'),
            (0, 0, 45, 45, 'US_state'),
            (0, 0, 48, 48, 'US_state'),
            (0, 0, 51, 51, 'US_state'),
            --south
            (0, 1, 1, 1, 'US_state'),
            (0, 1, 4, 4, 'US_state'),
            (0, 1, 8, 8, 'US_state'),
            (0, 1, 9, 9, 'US_state'),
            (0, 1, 10, 11, 'US_state'),
            (0, 1, 18, 19, 'US_state'),
            (0, 1, 21, 21, 'US_state'),
            (0, 1, 25, 25, 'US_state'),
            (0, 1, 34, 34, 'US_state'),
            (0, 1, 37, 37, 'US_state'),
            (0, 1, 41, 41, 'US_state'),
            (0, 1, 43, 44, 'US_state'),
            (0, 1, 47, 47, 'US_state'),
            (0, 1, 49, 49, 'US_state'),
            -- midwest
            (0, 2, 14, 17, 'US_state'),
            (0, 2, 23, 24, 'US_state'),
            (0, 2, 26, 26, 'US_state'),
            (0, 2, 28, 28, 'US_state'),
            (0, 2, 35, 36, 'US_state'),
            (0, 2, 42, 42, 'US_state'),
            (0, 2, 50, 50, 'US_state'),
            -- northeast
            (0, 3, 7, 7, 'US_state'),
            (0, 3, 20, 20, 'US_state'),
            (0, 3, 22, 22, 'US_state'),
            (0, 3, 30, 31, 'US_state'),
            (0, 3, 33, 33, 'US_state'),
            (0, 3, 39, 40, 'US_state'),
            (0, 3, 46, 46, 'US_state'),
            -- gender
            (1, 0, 0, 0, 'Gender'),
            (1, 1, 1, 1, 'Gender'),
            -- age
            (2, 0, 16, 24, 'Age'),
            (2, 1, 25, 39, 'Age'),
            (2, 2, 40, 54, 'Age'),
            (2, 3, 55, 74, 'Age'),
            -- household_income
            (3, 0, 0, 74999, 'Household_income'),
            (3, 1, 75000, 500000, 'Household_income')
    ) eating_out_us_cell_definitions
where response_set_identifier = 'US' and sp.product_identifier = 'eatingout';


-- Deploying: schemas\impl_weight\tables\_hardcoded_target_weights.sql
-- spike: hard code eatingout us target_weights: stores target weights for each cell in a response set
create or alter table impl_weight._hardcoded_target_weights (
    response_set_id number(38, 0) not null,
    cell_id number(38, 0) not null,
    target_weight number(20, 10) not null
) change_tracking = true;

insert into impl_weight._hardcoded_target_weights (response_set_id, cell_id, target_weight)
select rs.response_set_id, eating_out_us_weights.cell_id, eating_out_us_weights.target_weight from impl_response_set.response_sets rs
inner join impl_sub_product.sub_products sp on sp.sub_product_id = rs.sub_product_id
cross join
    (
        select
            column1 as cell_id, column2 as target_weight from values
        (0, 0.010548037), (16581375, 0.008787894), (65025, 0.017554428), (16646400, 0.016430842), (130050, 0.014649339), (16711425, 0.017093031), (195075, 0.018797635), (16776450, 0.015691753), (255, 0.011376841), (16581630, 0.009104036), (65280, 0.016336854), (16646655, 0.018092724), (130305, 0.013615469), (16711680, 0.018186712), (195330, 0.015644759), (16776705, 0.01545251), (1, 0.018502854), (16581376, 0.012547421), (65026, 0.029926689), (16646401, 0.021835162), (130051, 0.026692642), (16711426, 0.025804026), (195076, 0.037838785), (16776451, 0.020489422), (256, 0.017614238), (16581631, 0.013205339), (65281, 0.026803719), (16646656, 0.02323644), (130306, 0.023714925), (16711681, 0.025376807), (195331, 0.029747257), (16776706, 0.022048771), (2, 0.009321918), (16581377, 0.007463515), (65027, 0.015247445), (16646402, 0.013205339), (130052, 0.012320995), (16711427, 0.014884309), (195077, 0.019327386), (16776452, 0.01408541), (257, 0.008497385), (16581632, 0.008693906), (65282, 0.013606924), (16646657, 0.014294747), (130307, 0.011927954), (16711682, 0.015230356), (195332, 0.016131789), (16776707, 0.014709149), (3, 0.006920947), (16581378, 0.007553231), (65028, 0.011282853), (16646403, 0.01229109), (130053, 0.010090912), (16711428, 0.013897433), (195078, 0.015448238), (16776453, 0.013555658), (258, 0.006856865), (16581633, 0.008176971), (65283, 0.009894391), (16646658, 0.014025599), (130308, 0.008762261), (16711683, 0.013414676), (195333, 0.011915137), (16776708, 0.014217847)
    ) eating_out_us_weights
where response_set_identifier = 'US' and sp.product_identifier = 'eatingout';


-- Deploying: schemas\impl_weight\tables\_weighting_layers.sql
create or replace transient dynamic table impl_weight._weighting_layers (
    response_set_id integer,
    original_weighting_plan_id number(10, 0) not null,
    weighting_layer_id number(10, 0) not null,
    parent_weighting_layer_id number(10, 0),
    variable_identifier varchar(256) not null,
    entity_instance_id number(10, 0) not null,
    target_weight number(20, 10)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
select
    rs.response_set_id,
    wp.id as original_weighting_plan_id,
    wt.id as weighting_layer_id,
    wp.parent_weighting_target_id as parent_weighting_layer_id, -- null for root of entire tree
    --wp.is_weighting_group_root, -- can have multiple groups rooted within a tree
    wp.variable_identifier,
    wt.entity_instance_id,
    wt.target as target_weight
from raw_config.weighting_plans wp
join raw_config.weighting_targets wt
    on wt.parent_weighting_plan_id = wp.id
join impl_response_set.response_sets rs
    on rs.response_set_identifier = wp.subset_id
join impl_sub_product.sub_products sp
    on
        sp.sub_product_id = rs.sub_product_id
        and sp.product_identifier = wp.product_short_code
        and sp.sub_product_unqualified_identifier is not distinct from wp.sub_product_id;


-- Deploying: schemas\impl_response_set_unconfigured\tables\survey_mappings.sql
create or replace transient dynamic table impl_response_set_unconfigured.survey_mappings (
    response_set_id integer,
    survey_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select rs.response_set_id, f.value::int as survey_id
    from impl_response_set.response_sets rs,
        lateral flatten(input => rs.survey_ids) f
);


-- Deploying: schemas\impl_response_set\functions\is_readable_response_set_for_role.sql
create or replace function impl_response_set.is_readable_response_set_for_role(response_set_id integer)
returns boolean
language sql
memoizable -- noqa: PRS
as
$$
    CURRENT_ROLE() = 'LIVE__VUE__OWNER__D_ROLE' or
    current_user ilike '%@SAVANTA.COM' and exists (
        select 1
        from impl_response_set.response_sets rs
        where rs.response_set_id = response_set_id
          and array_size(rs.security_group_ids) = 0
    ) or exists (
        select 1
        from impl_response_set.response_set_role_mappings
        where response_set_id = response_set_id and role_name = current_role()
    )
$$;


-- Deploying: schemas\impl_response_set\tables\segments.sql
create or replace transient dynamic table impl_response_set.segments (
    response_set_id integer,
    segment_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        response_set_id,
        s.survey_segment_id as segment_id
    from raw_survey.survey_segments as s
    join (
        select
            response_set_id,
            f.key::int as survey_id,
            f.value::array as segment_names
        from impl_response_set.response_sets
        join lateral flatten(input => survey_id_to_allowed_segment_names) as f
    )
        as flattened on flattened.survey_id = s.survey_id
    and array_contains(s.segment_name::variant, flattened.segment_names)
);


-- Deploying: schemas\impl_response_set\tables\_entity_type_configurations.sql
create or replace transient dynamic table impl_response_set._entity_type_configurations (
    response_set_id integer,
    identifier varchar(256),
    display_name_singular varchar(256),
    display_name_plural varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with configured as (
        select
            sp.sub_product_id,
            etc.identifier,
            etc.display_name_singular,
            etc.display_name_plural
        from impl_sub_product.sub_products sp
        inner join raw_config.entity_type_configurations etc on
            etc.product_short_code = sp.product_identifier
            and etc.sub_product_id is not distinct from sp.sub_product_unqualified_identifier
    )

    select
        rs.response_set_id,
        c.identifier,
        c.display_name_singular,
        c.display_name_plural
    from impl_response_set.response_sets rs
    inner join configured c on rs.sub_product_id = c.sub_product_id
);

create or replace row access policy impl_response_set.readable_response_set_for_role_policy -- noqa: PRS
AS (response_set_id int)
returns boolean ->
    -- Indirection: Don't put any logic directly in here, otherwise all dependent objects have to have it removed and re-added on any change
    impl_response_set.is_readable_response_set_for_role(response_set_id);

-- Deploying: schemas\client_all__response_set\views\response_sets.sql
create or replace view client_all__response_set.response_sets (
    display_name,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select
        full_display_name as display_name,
        qualified_response_set_descriptor as response_set_descriptor,
        rs.response_set_id
    from impl_response_set.response_sets rs
    inner join impl_sub_product.sub_products sp on rs.sub_product_id = sp.sub_product_id
);


-- Deploying: schemas\impl_survey\procedures\init.sql
create or replace procedure impl_survey.init()
returns string
language sql
as
begin
    alter task impl_survey.incremental_update_survey_choice_set_root_ancestors resume;

    -- One-off initial populate: call the new procedure with all distinct survey_ids
    call impl_survey.update_choice_set_root_ancestors(
        select top 1 array_unique_agg(survey_id) from raw_survey.choice_sets
    );

    return 'done';
end;

-- Deploying: schemas\impl_weight\tables\target_weights.sql
create or replace transient dynamic table impl_weight.target_weights (
    response_set_id integer,
    cell_id integer,
    target_weight number(20, 10)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with normalized as (
        select
            response_set_id,
            cell_id,
            div0(tw.target_weight::number(25, 15), sum(tw.target_weight) over (partition by response_set_id)) as precision_target_weight,
            div0(tw.target_weight::number(25, 15), sum(tw.target_weight) over (partition by response_set_id))::number(20, 10) as rounded_target_weight
        from
            (
                select
                    response_set_id,
                    root_weighting_plan_id,
                    cell_id,
                    target_weight
                from impl_weight._cell_definitions
                -- SPIKE: hardcoded target weights for eatingout US
                where response_set_id != 80
                union all
                select
                    response_set_id,
                    0 as root_weighting_plan_id,
                    cell_id,
                    target_weight
                from impl_weight._hardcoded_target_weights
                where response_set_id = 80
            ) tw
    ),

    proposed_fixup as (
        select
            response_set_id,
            cell_id,
            rounded_target_weight,
            (
                1
                + rounded_target_weight
                - (sum(rounded_target_weight) over (partition by response_set_id))
            )::number(20, 10) as proposed_fixup_weight,
            div0(
                abs(
                    1
                    + rounded_target_weight
                    - (sum(rounded_target_weight) over (partition by response_set_id))
                )::number(20, 10),
                precision_target_weight
            ) as effect_of_fixup
        from normalized
    )

    -- The intent here is to ensure a set of fixed precision weights that sum exactly to 1, and are as close to the original ratios as possible
    -- This ensures weighted and unweighted sample sizes will match downstream
    select
        response_set_id,
        cell_id,
        case
            when row_number() over (
                partition by response_set_id
                order by effect_of_fixup asc
            ) = 1 then proposed_fixup_weight
            else rounded_target_weight
        end as target_weight
    from proposed_fixup
);


-- Deploying: schemas\impl_weight\procedures\update_cell_definitions.sql
create or replace procedure impl_weight.update_cell_definitions(response_set_ids array)
returns string
language sql
as
begin
    -- Early exit if response_set_ids array is empty
    if (array_size(:response_set_ids) = 0) then
        return 'done';
    end if;

    create or replace temporary table impl_weight.__temp_response_sets_to_update (response_set_id_to_update int) as
    select distinct to_number(value) as response_set_id_to_update
    from table(flatten(input => :response_set_ids));

    -- Remove existing cell definitions for these response sets
    delete from impl_weight._cell_definitions
    where response_set_id in (select response_set_id_to_update from impl_weight.__temp_response_sets_to_update);

    -- Insert refreshed rows using hierarchical query to build paths
    insert into impl_weight._cell_definitions (response_set_id, root_weighting_plan_id, cell_id, target_weight, weighting_parts)
    select
        wl.response_set_id,
        connect_by_root original_weighting_plan_id as root_weighting_plan_id,
        weighting_layer_id as cell_id,
        wl.target_weight,
        parse_json('{' || ltrim(sys_connect_by_path('"' || wl.variable_identifier || '":' || wl.entity_instance_id, ','), ',') || '}') as weighting_parts
    from impl_weight._weighting_layers wl
    join impl_weight.__temp_response_sets_to_update tsu
        on wl.response_set_id = tsu.response_set_id_to_update
    where wl.target_weight is not null
    start with wl.parent_weighting_layer_id is null
    connect by prior wl.weighting_layer_id = wl.parent_weighting_layer_id;

    drop table if exists impl_weight.__temp_response_sets_to_update;

    return 'done';
end;

-- Deploying: schemas\impl_weight\streams\_weighting_layers_stream.sql
create or replace stream impl_weight._weighting_layers_stream on dynamic table impl_weight._weighting_layers;

-- Deploying: schemas\impl_response_set_unconfigured\tables\_all_questions_including_confidential.sql
create or replace transient dynamic table impl_response_set_unconfigured._all_questions_including_confidential (
    response_set_id integer,
    var_code varchar(256),
    question_id integer,
    survey_id integer,
    question_text varchar(2000),
    is_confidential boolean,
    is_multiple_choice boolean,
    min_value integer,
    max_value integer,
    item_number integer,
    number_format varchar(256),
    opaque_question_layout_signature integer comment 'Opaque value. When different, the data layout is definitely not compatible. When the same it is the same shape. i.e. choice sets in the same slots'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        rss.response_set_id,
        q.var_code,
        q.question_id,
        q.survey_id,
        q.question_text,
        q.is_confidential,
        q.is_multiple_choice,
        q.min_value,
        q.max_value,
        q.item_number,
        q.number_format,
        q.opaque_question_layout_signature
    from impl_survey.all_questions_including_confidential q
    join impl_response_set_unconfigured.survey_mappings rss on q.survey_id = rss.survey_id
);


-- Deploying: schemas\impl_response_set\tables\responses.sql
create or replace transient dynamic table impl_response_set.responses (
    response_set_id integer not null,
    response_id integer not null,
    survey_id integer not null,
    segment_id integer not null,
    survey_completed date,
    answers_enabled boolean not null
) cluster by (trunc(response_id, -3)) -- Premature optimization: Cluster roughly by response_id for the join to answers
target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        rss.response_set_id,
        sr.response_id,
        sr.survey_id,
        sr.segment_id,
        cast(sr.last_change_time as date) as survey_completed,
        rsae.response_set_id is not null as answers_enabled
    from raw_survey.survey_response sr
    inner join
        impl_response_set.segments rss
        on sr.segment_id = rss.segment_id
    left outer join raw.response_set_answers_enabled rsae
        on rss.response_set_id = rsae.response_set_id
    where sr.status = 6 and sr.archived = false
);


-- Deploying: schemas\impl_weight\tasks\incremental_update_cell_definitions.sql
create or replace task impl_weight.incremental_update_cell_definitions
    -- todo: decide whether this should be in warehouse or serverless. probably best to bound cost by using warehouse that's on anyway
    --target_completion_interval='1 MINUTE'
    warehouse = warehouse_xsmall
when
    system$stream_has_data ('impl_weight._weighting_layers_stream')
as begin
    call impl_weight.update_cell_definitions(
        select array_agg(distinct response_set_id)
        from impl_weight._weighting_layers_stream
        where metadata$action in ('INSERT', 'UPDATE', 'DELETE')
    );
end;


-- Deploying: schemas\impl_response_set_unconfigured\tables\canonical_question_alternative_mappings.sql
create or replace transient dynamic table impl_response_set_unconfigured.canonical_question_alternative_mappings (
    response_set_id integer,
    alternative_question_id integer,
    canonical_question_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select distinct
        rsq.response_set_id,
        rsq.question_id as alternative_question_id,
        first_value(rsq.question_id)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id asc
            )
            as canonical_question_id
    from impl_response_set_unconfigured._all_questions_including_confidential rsq
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_canonical_choice_set_alternative_initial_mappings.sql
create or replace transient dynamic table impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings (
    response_set_id integer,
    alternative_choice_set_id integer,
    canonical_choice_set_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select distinct
        rsq.response_set_id,
        qccs.canonical_choice_set_id as alternative_choice_set_id,
        -- Merge questions which have the same var_code from different surveys, so long as their data layout is compatible
        -- Pick a canonical choice set id to represent the choice sets in the same index of the dimensions. e.g. sectionchoiceset id from each question
        first_value(qccs.canonical_choice_set_id) over (
            -- TODO: Feels like we shouldn't have to repeat this since the question merging should have a resulting useable mapping
            partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature, qccs.index
            order by rsq.survey_id
        ) as canonical_choice_set_id
    from impl_survey.canonical_choice_set_locations qccs
    join impl_response_set_unconfigured._all_questions_including_confidential rsq on qccs.question_id = rsq.question_id
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_core_canonical_questions_including_confidential.sql
create or replace transient dynamic table impl_response_set_unconfigured._core_canonical_questions_including_confidential (
    response_set_id integer,
    var_code varchar(256),
    is_confidential boolean,
    canonical_question_id integer,
    canonical_survey_id integer,
    opaque_question_layout_signature integer,
    is_multiple_choice boolean,
    latest_question_text varchar(2000),
    internal_question_metadata variant comment 'Unsupported extra information. Not client facing. Sometimes has confusing values, use with caution.'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- In the case of differing data_layout_signature, a var_code can appear twice, though with a different canonical_survey_id
    select distinct
        rsq.response_set_id,
        rsq.var_code,
        max(rsq.is_confidential)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
            )
            as is_confidential,
        first_value(rsq.question_id)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id asc
            )
            as canonical_question_id,
        first_value(rsq.survey_id)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id asc
            )
            as canonical_survey_id,
        opaque_question_layout_signature,
        first_value(rsq.is_multiple_choice)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id desc
            )
            as is_multiple_choice,
        first_value(rsq.question_text)
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id desc
            )
            as latest_question_text,
        first_value(object_construct(
            'min_value', rsq.min_value,
            'max_value', rsq.max_value,
            'item_number', rsq.item_number,
            'number_format', rsq.number_format
        ))
            over (
                partition by rsq.response_set_id, rsq.var_code, rsq.opaque_question_layout_signature
                order by rsq.survey_id desc
            )
            as internal_question_metadata
    from impl_response_set_unconfigured._all_questions_including_confidential rsq
    where rsq.is_confidential = false
);


-- Deploying: schemas\impl_result\tables\response_set_settings.sql

create or replace transient dynamic table impl_result.response_set_settings (
    response_set_id integer,
    first_data_date date,
    last_full_data_date date
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as -- response_set_settings: defines the start/end date for each response set
with latest_full_day as (
    select dateadd(day, -1, cast(max(last_sync_timestamp_utc) as date)) as the_date
    from airflow.ct_tidemarks where table_key ilike '%.dbo.surveyResponse'
    -- SPIKE: last_sync_timestamp_utc DOESN'T mean we have all data up to that point.
    -- We'll pull through the timestamp of the last change too at some point
)

select
    r.response_set_id,
    min(r.survey_completed) as first_data_date,
    least(max(r.survey_completed), lfd.the_date) as last_full_data_date
from impl_response_set.responses as r
cross join latest_full_day as lfd
group by r.response_set_id, lfd.the_date;


-- Deploying: schemas\client_all__response_set\views\responses.sql
create or replace secure view client_all__response_set.responses (
    response_id,
    survey_completed,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select distinct
        r.response_id,
        r.survey_completed,
        rs.response_set_descriptor,
        rs.response_set_id
    from impl_response_set.responses as r
    inner join client_all__response_set.response_sets as rs
        on r.response_set_id = rs.response_set_id
);


-- Deploying: schemas\impl_weight\procedures\init.sql
create or replace procedure impl_weight.init()
returns string
language sql
as
begin
    
    alter task impl_weight.incremental_update_cell_definitions resume;

    -- Ensure up to date data in the dynamic table before initial population
    alter dynamic table impl_weight._weighting_layers refresh;
    
    call impl_weight.update_cell_definitions(
        select top 1 array_unique_agg(response_set_id) from impl_weight._weighting_layers
    );

    return 'done';
end;


-- Deploying: schemas\impl_response_set_unconfigured\procedures\update_response_set_canonical_choice_set_mappings.sql
create or replace procedure impl_response_set_unconfigured.update_response_set_canonical_choice_set_mappings(response_set_ids array)
returns string
language sql
as
begin
    -- Early exit if response_set_ids array is empty
    if (array_size(:response_set_ids) = 0) then
        return 'done';
    end if;

    create or replace temporary table impl_response_set_unconfigured.__temp_response_sets_to_update (response_set_id int) as
    select distinct to_number(value) as response_set_id
    from table(flatten(input => :response_set_ids));

    -- Delete old rows for those response sets
    delete from impl_response_set_unconfigured.canonical_choice_set_alternative_mappings
    where response_set_id in (select response_set_id from impl_response_set_unconfigured.__temp_response_sets_to_update);

    -- Re-insert refreshed rows for those response sets
    insert into impl_response_set_unconfigured.canonical_choice_set_alternative_mappings (response_set_id, canonical_choice_set_id, alternative_choice_set_id)
    with
    initial_mappings as (
        select response_set_id, canonical_choice_set_id, alternative_choice_set_id
        from impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings
        -- To reinitialize the whole table in one go you could remove the WHERE below and refresh the dynamic table first
        where response_set_id in (select response_set_id from impl_response_set_unconfigured.__temp_response_sets_to_update)
    ),

    initial_mappings_no_cycles as (
        select response_set_id, canonical_choice_set_id, alternative_choice_set_id
        from initial_mappings
        where canonical_choice_set_id != alternative_choice_set_id
    ),

    initial_roots as (
        select distinct response_set_id, canonical_choice_set_id
        from initial_mappings_no_cycles
        where canonical_choice_set_id not in (
            select imnc.alternative_choice_set_id
            from initial_mappings_no_cycles imnc
        )
    ),

    closed_mappings as (
        select distinct
            response_set_id,
            connect_by_root(canonical_choice_set_id) as canonical_choice_set_id,
            alternative_choice_set_id
        from initial_mappings_no_cycles
        start with canonical_choice_set_id in (select canonical_choice_set_id from initial_roots)
        connect by prior alternative_choice_set_id = canonical_choice_set_id
        and prior response_set_id = response_set_id
    )

    select
        im.response_set_id,
        min(coalesce(cm.canonical_choice_set_id, im.canonical_choice_set_id)) as canonical_choice_set_id,
        im.alternative_choice_set_id
    from initial_mappings im
    left join closed_mappings cm
        on
            im.alternative_choice_set_id = cm.alternative_choice_set_id
            and im.response_set_id = cm.response_set_id
    group by im.response_set_id, im.alternative_choice_set_id;

    drop table if exists impl_response_set_unconfigured.__temp_response_sets_to_update;

    return 'done';
end;


-- Deploying: schemas\impl_response_set_unconfigured\streams\_canonical_choice_set_alternative_initial_mappings_stream.sql
create or replace stream impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings_stream on dynamic table impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings; -- noqa: PRS


-- Deploying: schemas\impl_response_set_unconfigured\tables\question_canonical_choice_set_locations.sql
create or replace transient dynamic table impl_response_set_unconfigured.question_canonical_choice_set_locations (
    response_set_id integer,
    canonical_question_id integer,
    canonical_survey_id integer,
    canonical_choice_set_id integer,
    choice_source varchar(256),
    index integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        rsq.response_set_id,
        rsq.canonical_question_id,
        rsq.canonical_survey_id,
        rscs_map.canonical_choice_set_id,
        cs.choice_source,
        cs.index
    from impl_response_set_unconfigured._core_canonical_questions_including_confidential rsq
    inner join impl_survey.canonical_choice_set_locations cs
        on cs.question_id = rsq.canonical_question_id
    join impl_response_set_unconfigured.canonical_choice_set_alternative_mappings rscs_map
        on
            rsq.response_set_id = rscs_map.response_set_id
            and cs.canonical_choice_set_id = rscs_map.alternative_choice_set_id
);


-- Deploying: schemas\impl_result\tables\dates.sql
create or replace transient dynamic table impl_result.dates (
    response_set_id integer,
    the_date date
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
-- generates all dates for each response set so we can calculate running totals more easily
select response_set_id, dateadd(day, number, first_data_date) as the_date
from impl_result.response_set_settings cross join impl_result._integers
where dateadd(day, number, first_data_date) <= last_full_data_date;


-- Deploying: schemas\impl_response_set_unconfigured\tasks\incremental_update_response_set_canonical_choice_set_mappings.sql
create or replace task impl_response_set_unconfigured.incremental_update_response_set_canonical_choice_set_mappings
    warehouse = warehouse_xsmall
when system$stream_has_data ('impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings_stream')
as begin
    call impl_response_set_unconfigured.update_response_set_canonical_choice_set_mappings(
        select array_agg(distinct response_set_id)
        from impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings_stream
        where metadata$action in ('INSERT', 'UPDATE', 'DELETE')
    );
end;


-- Deploying: schemas\impl_response_set_unconfigured\tables\canonical_choice_sets.sql
create or replace transient dynamic table impl_response_set_unconfigured.canonical_choice_sets (
    response_set_id integer,
    canonical_choice_set_id integer comment 'Only unique within response set',
    canonical_survey_id integer,
    name varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with distinct_canonical_choice_sets as (
        -- Canonical choice set maps to many alternatives
        select distinct
            response_set_id,
            canonical_choice_set_id,
            canonical_survey_id
        from impl_response_set_unconfigured.question_canonical_choice_set_locations
    )

    select
        dccs.response_set_id,
        dccs.canonical_choice_set_id,
        dccs.canonical_survey_id,
        cs.name
    from distinct_canonical_choice_sets dccs
    join raw_survey.choice_sets cs
        on dccs.canonical_choice_set_id = cs.choice_set_id
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\canonical_questions_including_confidential.sql
create or replace transient dynamic table impl_response_set_unconfigured.canonical_questions_including_confidential (
    response_set_id integer,
    is_confidential boolean,
    opaque_question_layout_signature integer,
    question_var_code varchar(256),
    long_text varchar(2000),
    canonical_question_id integer,
    canonical_survey_id integer,
    asked_canonical_choice_set_id_1 integer,
    asked_canonical_choice_set_id_2 integer,
    asked_canonical_choice_set_id_3 integer,
    answer_canonical_choice_set_id integer,
    is_multiple_choice boolean,
    internal_question_metadata variant
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        q.response_set_id,
        max(q.is_confidential) as is_confidential,
        q.opaque_question_layout_signature,
        q.var_code as question_var_code,
        -- TODO: Keep track of choice_set_id for various known tags such as #PAGECHOICEID#, so we can replace them at an appropriate location with the entity identifier
        q.latest_question_text as long_text,
        q.canonical_question_id,
        q.canonical_survey_id,
        max(
            case
                when
                    cs.index = 0 and cs.choice_source != 'AnswerChoiceId'
                    then cs.canonical_choice_set_id
                else null
            end
        ) as asked_canonical_choice_set_id_1,
        max(
            case
                when
                    cs.index = 1 and cs.choice_source != 'AnswerChoiceId'
                    then cs.canonical_choice_set_id
                else null
            end
        ) as asked_canonical_choice_set_id_2,
        max(
            case
                when
                    cs.index = 2 and cs.choice_source != 'AnswerChoiceId'
                    then cs.canonical_choice_set_id
                else null
            end
        ) as asked_canonical_choice_set_id_3,
        max(
            case
                when
                    cs.choice_source = 'AnswerChoiceId'
                    then cs.canonical_choice_set_id
                else null
            end
        ) as answer_canonical_choice_set_id,
        max(q.is_multiple_choice) as is_multiple_choice,
        min(q.internal_question_metadata) as internal_question_metadata
    from impl_response_set_unconfigured._core_canonical_questions_including_confidential q
    -- Left join to keep the questions with no choice sets
    left join impl_response_set_unconfigured.question_canonical_choice_set_locations cs
        on q.canonical_question_id = cs.canonical_question_id
    group by
        q.response_set_id,
        q.var_code,
        q.opaque_question_layout_signature,
        q.latest_question_text,
        q.canonical_question_id,
        q.canonical_survey_id
);


-- Deploying: schemas\impl_response_set_unconfigured\procedures\init.sql
create or replace procedure impl_response_set_unconfigured.init()
returns string
language sql
as
begin
    alter task impl_response_set_unconfigured.incremental_update_response_set_canonical_choice_set_mappings resume;

    -- Ensure up to date data in the dynamic table before initial population
    alter dynamic table impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings refresh;

    call impl_response_set_unconfigured.update_response_set_canonical_choice_set_mappings(
        select top 1 array_unique_agg(response_set_id) from impl_response_set_unconfigured._canonical_choice_set_alternative_initial_mappings
    );

    return 'done';
end;


-- Deploying: schemas\impl_response_set\tables\_joined_variables_including_confidential.sql
create or replace transient dynamic table impl_response_set._joined_variables_including_confidential (
    response_set_id integer,
    is_confidential boolean,
    variable_identifier varchar(256),
    asked_entity_type_identifier_1 varchar(256),
    asked_entity_type_identifier_2 varchar(256),
    asked_entity_type_identifier_3 varchar(256),
    answer_entity_type_identifier varchar(256),
    long_text varchar(2000),
    variable_configuration_id integer,
    canonical_question_id integer,
    question_var_code varchar(256),
    canonical_survey_id integer,
    is_multiple_choice boolean,
    asked_canonical_choice_set_id_1 integer,
    asked_canonical_choice_set_id_2 integer,
    asked_canonical_choice_set_id_3 integer,
    answer_canonical_choice_set_id integer,
    variable_identifier_exists_matching_var_code boolean,
    internal_question_metadata variant
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with existing_identifiers as (
        select distinct
            sub_product_id,
            variable_identifier
        from impl_sub_product.variable_configurations
    )

    select distinct -- todo, check why distinct is needed, ensure non-confidential question can't pull through a confidential one by mistake
        uqv.response_set_id,
        uqv.is_confidential,
        vc.variable_identifier,
        -- TODO left join to get canonical choice set name as fallback
        vc.asked_entity_type_identifier_1,
        vc.asked_entity_type_identifier_2,
        vc.asked_entity_type_identifier_3,
        vc.answer_entity_type_identifier,
        uqv.long_text, -- question text for questions
        vc.variable_configuration_id, -- If not set, this variable is unconfigured and hence subject to be overridden by later surveys
        -- Extra question metadata for convenience
        uqv.canonical_question_id,
        uqv.question_var_code,
        uqv.canonical_survey_id,
        uqv.is_multiple_choice,
        uqv.asked_canonical_choice_set_id_1,
        uqv.asked_canonical_choice_set_id_2,
        uqv.asked_canonical_choice_set_id_3,
        uqv.answer_canonical_choice_set_id,
        ei.variable_identifier is not null as variable_identifier_exists_matching_var_code,
        uqv.internal_question_metadata
    from impl_response_set.response_sets rs
    inner join impl_response_set_unconfigured.canonical_questions_including_confidential uqv on uqv.response_set_id = rs.response_set_id
    left join existing_identifiers ei on ei.sub_product_id = rs.sub_product_id and ei.variable_identifier = uqv.question_var_code
    left join impl_sub_product.variable_configurations vc
        on
            uqv.question_var_code = vc.question_var_code and rs.sub_product_id = vc.sub_product_id and uqv.opaque_question_layout_signature = vc.opaque_question_layout_signature
);


-- Deploying: schemas\impl_response_set\tables\_entity_type_configuration_alternative_choice_set_mappings.sql
create or replace transient dynamic table impl_response_set._entity_type_configuration_alternative_choice_set_mappings (
    response_set_id integer,
    entity_type_identifier varchar(256),
    canonical_choice_set_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with cte as (
        select
            response_set_id,
            asked_entity_type_identifier_1 as entity_type_identifier,
            asked_canonical_choice_set_id_1 as canonical_choice_set_id
        from impl_response_set._joined_variables_including_confidential
        where asked_entity_type_identifier_1 is not null

        union all

        select
            response_set_id,
            asked_entity_type_identifier_2 as entity_type_identifier,
            asked_canonical_choice_set_id_2 as canonical_choice_set_id
        from impl_response_set._joined_variables_including_confidential
        where asked_entity_type_identifier_2 is not null

        union all

        select
            response_set_id,
            asked_entity_type_identifier_3 as entity_type_identifier,
            asked_canonical_choice_set_id_3 as canonical_choice_set_id
        from impl_response_set._joined_variables_including_confidential
        where asked_entity_type_identifier_3 is not null

        union all

        select
            response_set_id,
            answer_entity_type_identifier as entity_type_identifier,
            answer_canonical_choice_set_id as canonical_choice_set_id
        from impl_response_set._joined_variables_including_confidential
        where answer_entity_type_identifier is not null
    )

    select distinct
        response_set_id,
        entity_type_identifier,
        canonical_choice_set_id
    from cte
);


-- Deploying: schemas\impl_response_set\tables\_entity_type_configuration_alternative_choice_set_mappings_2.sql
create or replace transient dynamic table impl_response_set._entity_type_configuration_alternative_choice_set_mappings_2 (
    response_set_id integer,
    entity_type_identifier varchar(256),
    canonical_choice_set_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- We need to outer join this twice, but snowflake does not allow that, so make a copy
    -- TODO: Look for better solutions, can we pull into a CTE in the consumer, then left join that multiple times?
    select response_set_id, entity_type_identifier, canonical_choice_set_id
    from impl_response_set._entity_type_configuration_alternative_choice_set_mappings
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_unique_choice_set_identifiers.sql
create or replace transient dynamic table impl_response_set_unconfigured._unique_choice_set_identifiers (
    response_set_id integer,
    canonical_choice_set_id integer,
    default_entity_type_identifier varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- Prefer existing configured identifier, then the choice set name, then appending survey id suffix if needed
    with cte as (
        select
            ccs.response_set_id,
            ccs.canonical_choice_set_id,
            coalesce(
                matching_id.entity_type_identifier,
                ccs.name ||
                case
                    when
                        clashing_identifier.entity_type_identifier is not null
                        or row_number() over (partition by ccs.response_set_id, ccs.name order by ccs.canonical_survey_id) = 1
                        then ''
                    else '_' || ccs.canonical_survey_id
                end
            ) as default_entity_type_identifier
        from impl_response_set_unconfigured.canonical_choice_sets ccs
        left join impl_response_set._entity_type_configuration_alternative_choice_set_mappings matching_id
            on
                matching_id.response_set_id = ccs.response_set_id
                and matching_id.canonical_choice_set_id = ccs.canonical_choice_set_id
        left join impl_response_set._entity_type_configuration_alternative_choice_set_mappings_2
            clashing_identifier on clashing_identifier.response_set_id = ccs.response_set_id
        and clashing_identifier.entity_type_identifier = ccs.name
    )

    select distinct
        response_set_id, canonical_choice_set_id, default_entity_type_identifier
    from cte
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_unique_choice_set_identifiers_2.sql
create or replace transient dynamic table impl_response_set_unconfigured._unique_choice_set_identifiers_2 (
    response_set_id integer,
    canonical_choice_set_id integer,
    default_entity_type_identifier varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select response_set_id, canonical_choice_set_id, default_entity_type_identifier
    from impl_response_set_unconfigured._unique_choice_set_identifiers
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_unique_choice_set_identifiers_3.sql
create or replace transient dynamic table impl_response_set_unconfigured._unique_choice_set_identifiers_3 (
    response_set_id integer,
    canonical_choice_set_id integer,
    default_entity_type_identifier varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select response_set_id, canonical_choice_set_id, default_entity_type_identifier
    from impl_response_set_unconfigured._unique_choice_set_identifiers
);


-- Deploying: schemas\impl_response_set_unconfigured\tables\_unique_choice_set_identifiers_4.sql
create or replace transient dynamic table impl_response_set_unconfigured._unique_choice_set_identifiers_4 (
    response_set_id integer,
    canonical_choice_set_id integer,
    default_entity_type_identifier varchar(256)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select response_set_id, canonical_choice_set_id, default_entity_type_identifier
    from impl_response_set_unconfigured._unique_choice_set_identifiers
);


-- Deploying: schemas\impl_response_set\tables\_question_variables_including_confidential.sql
create or replace transient dynamic table impl_response_set._question_variables_including_confidential (
    response_set_id integer,
    is_confidential boolean,
    variable_identifier varchar(256),
    asked_entity_type_identifier_1 varchar(256),
    asked_entity_type_identifier_2 varchar(256),
    asked_entity_type_identifier_3 varchar(256),
    answer_entity_type_identifier varchar(256),
    long_text varchar(2000),
    variable_configuration_id integer,
    -- Extra question metadata for convenience
    canonical_question_id integer,
    question_var_code varchar(256),
    canonical_survey_id integer,
    is_multiple_choice boolean,
    asked_canonical_choice_set_id_1 integer,
    asked_canonical_choice_set_id_2 integer,
    asked_canonical_choice_set_id_3 integer,
    answer_canonical_choice_set_id integer,
    internal_question_metadata variant
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        jv.response_set_id,
        jv.is_confidential,
        case
            when jv.variable_identifier is not null then jv.variable_identifier
            when variable_identifier_exists_matching_var_code then jv.question_var_code || '_' || jv.canonical_survey_id
            else jv.question_var_code
        end as variable_identifier,
        -- Get or generate entity type identifiers
        coalesce(jv.asked_entity_type_identifier_1, fc1.default_entity_type_identifier) as asked_entity_type_identifier_1,
        coalesce(jv.asked_entity_type_identifier_2, fc2.default_entity_type_identifier) as asked_entity_type_identifier_2,
        coalesce(jv.asked_entity_type_identifier_3, fc3.default_entity_type_identifier) as asked_entity_type_identifier_3,
        coalesce(jv.answer_entity_type_identifier, fca.default_entity_type_identifier, iff(jv.is_multiple_choice, 'Is_Checked', null)) as answer_entity_type_identifier,
        jv.long_text,
        jv.variable_configuration_id,
        jv.canonical_question_id,
        jv.question_var_code,
        jv.canonical_survey_id,
        jv.is_multiple_choice,
        jv.asked_canonical_choice_set_id_1,
        jv.asked_canonical_choice_set_id_2,
        jv.asked_canonical_choice_set_id_3,
        jv.answer_canonical_choice_set_id,
        jv.internal_question_metadata
    from impl_response_set._joined_variables_including_confidential jv
    left join impl_response_set_unconfigured._unique_choice_set_identifiers fc1
        on
            fc1.canonical_choice_set_id = jv.asked_canonical_choice_set_id_1
            and fc1.response_set_id = jv.response_set_id
    left join impl_response_set_unconfigured._unique_choice_set_identifiers_2 fc2
        on
            fc2.canonical_choice_set_id = jv.asked_canonical_choice_set_id_2
            and fc2.response_set_id = jv.response_set_id
    left join impl_response_set_unconfigured._unique_choice_set_identifiers_3 fc3
        on
            fc3.canonical_choice_set_id = jv.asked_canonical_choice_set_id_3
            and fc3.response_set_id = jv.response_set_id
    left join impl_response_set_unconfigured._unique_choice_set_identifiers_4 fca
        on
            fca.canonical_choice_set_id = jv.answer_canonical_choice_set_id
            and fca.response_set_id = jv.response_set_id
);


-- Deploying: schemas\impl_response_set\tables\variables.sql
create or replace transient dynamic table impl_response_set.variables (
    response_set_id integer,
    variable_identifier varchar(256),
    asked_entity_type_identifier_1 varchar(256),
    asked_entity_type_identifier_2 varchar(256),
    asked_entity_type_identifier_3 varchar(256),
    answer_entity_type_identifier varchar(256),
    long_text varchar(2000),
    variable_configuration_id integer,
    question_is_multiple_choice boolean,
    internal_question_metadata variant comment 'Unsupported extra information. Not client facing. Sometimes has confusing values, use with caution.'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        qv.response_set_id,
        qv.variable_identifier,
        qv.asked_entity_type_identifier_1,
        qv.asked_entity_type_identifier_2,
        qv.asked_entity_type_identifier_3,
        qv.answer_entity_type_identifier,
        qv.long_text, -- question text for questions
        qv.variable_configuration_id,
        qv.is_multiple_choice,
        qv.internal_question_metadata
    from impl_response_set._question_variables_including_confidential as qv
    where not qv.is_confidential
);


-- Deploying: schemas\impl_response_set\tables\_entity_type_alternative_choice_set_mappings.sql
create or replace transient dynamic table impl_response_set._entity_type_alternative_choice_set_mappings (
    response_set_id integer not null,
    entity_type_identifier varchar(256) not null,
    canonical_choice_set_id integer null comment 'Null for Is_Checked entity type'
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- This is a lot like _entity_type_configuration_alternative_choice_set_mappings but uses _question_variables instead of _joined_variables which has generated identifiers for unconfigured items
    with mappings as (
        select
            qv.response_set_id,
            qv.is_multiple_choice,
            qv.asked_entity_type_identifier_1 as entity_type_identifier,
            qv.asked_canonical_choice_set_id_1 as canonical_choice_set_id
        from impl_response_set._question_variables_including_confidential qv

        union all

        select
            qv.response_set_id,
            qv.is_multiple_choice,
            qv.asked_entity_type_identifier_2 as entity_type_identifier,
            qv.asked_canonical_choice_set_id_2 as canonical_choice_set_id
        from impl_response_set._question_variables_including_confidential qv

        union all

        select
            qv.response_set_id,
            qv.is_multiple_choice,
            qv.asked_entity_type_identifier_3 as entity_type_identifier,
            qv.asked_canonical_choice_set_id_3 as canonical_choice_set_id
        from impl_response_set._question_variables_including_confidential qv

        union all

        select
            qv.response_set_id,
            qv.is_multiple_choice,
            qv.answer_entity_type_identifier as entity_type_identifier,
            qv.answer_canonical_choice_set_id as canonical_choice_set_id
        from impl_response_set._question_variables_including_confidential qv

    )

    -- The same identifier can appear for different canonical_choice_set_ids if previous stages didn't connect them but the configuration does
    select distinct response_set_id, entity_type_identifier, canonical_choice_set_id
    from mappings
    where entity_type_identifier is not null and (canonical_choice_set_id is not null or is_multiple_choice)
);


-- Deploying: schemas\impl_response_set\tables\_variable_canonical_question_mappings.sql
create or replace transient dynamic table impl_response_set._variable_canonical_question_mappings (
    response_set_id integer,
    variable_identifier varchar(256),
    canonical_question_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    --- Speculative perf: Make sure tables that variable_answers depends on don't change often so changes are resolved before joining the big table
    select distinct -- TODO Figure out why the table this depends on isn't unique!
        qv.response_set_id,
        qv.variable_identifier,
        qv.canonical_question_id
    from impl_response_set._question_variables_including_confidential as qv
);


-- Deploying: schemas\client_all__response_set\views\variables.sql
create or replace secure view client_all__response_set.variables (
    -- Definition
    variable_identifier,
    answer_entity_type_identifier,
    asked_entity_type_identifier_1,
    asked_entity_type_identifier_2,
    asked_entity_type_identifier_3,
    response_set_descriptor,
    response_set_id,
    -- Human facing info / convenience additions
    long_text,
    asked_entity_type_identifiers,
    question_metadata
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select
        -- Definition
        qv.variable_identifier,
        qv.answer_entity_type_identifier,
        qv.asked_entity_type_identifier_1,
        qv.asked_entity_type_identifier_2,
        qv.asked_entity_type_identifier_3,
        rs.response_set_descriptor,
        rs.response_set_id,
        -- Human facing info / convenience additions
        qv.long_text,
        -- Convenience
        array_construct_compact(
            qv.asked_entity_type_identifier_1,
            qv.asked_entity_type_identifier_2,
            qv.asked_entity_type_identifier_3
        ) as asked_entity_type_identifiers,
        case
            when
                qv.internal_question_metadata is not null
                -- These values are often spurious/unused, so only include for certain checked cases until we clean them better.
                and rs.response_set_descriptor like 'brandvue_%'
                then object_pick(internal_question_metadata, 'min_value', 'max_value')::variant
            else null
        end as question_metadata
    from impl_response_set.variables as qv
    inner join client_all__response_set.response_sets as rs
        on qv.response_set_id = rs.response_set_id
);


-- Deploying: schemas\impl_response_set\tables\entity_instances.sql
create or replace transient dynamic table impl_response_set.entity_instances (
    response_set_id integer,
    entity_type_identifier varchar(256),
    entity_instance_id integer,
    name varchar(2000),
    enabled boolean,
    start_date date
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with base_entity_instances as (
        -- Distinct because response_set_entity_type_first_choice_set_mappings can still have multiple mappings per entity_type_identifier
        select distinct
            et_cs_map.response_set_id,
            et_cs_map.entity_type_identifier,
            cc.survey_choice_id as entity_instance_id,
            first_value(
                coalesce(get(eic.display_name_override_by_subset, et_cs_map.response_set_id), cc.display_name)
            ) over (partition by et_cs_map.response_set_id, et_cs_map.entity_type_identifier, cc.survey_choice_id order by cc.latest_survey_id desc)
                as name,
            coalesce(get(eic.enabled_by_subset, et_cs_map.response_set_id), true) as enabled,
            get(eic.start_date_by_subset, et_cs_map.response_set_id) as start_date
        from impl_response_set._entity_type_alternative_choice_set_mappings et_cs_map
        inner join impl_response_set_unconfigured.canonical_choices cc on cc.canonical_choice_set_id = et_cs_map.canonical_choice_set_id
        inner join impl_response_set.response_sets rs on rs.response_set_id = et_cs_map.response_set_id
        left join impl_sub_product.entity_instance_configurations eic
            on
                rs.sub_product_id = eic.sub_product_id
                and et_cs_map.entity_type_identifier = eic.entity_type_identifier
                and cc.survey_choice_id = eic.entity_instance_id
    ),

    first_ids_for_names as (
        select distinct
            response_set_id,
            entity_type_identifier,
            name,
            -- If two names clash, we'll prefer keeping the one with the lowest id that's enabled
            -- So if something is getting renamed, in the config table, you'll need to either disable or rename the one it clashes with
            first_value(entity_instance_id) over (
                partition by response_set_id, entity_type_identifier, name
                order by enabled desc, entity_instance_id asc
            ) as first_id_for_name
        from base_entity_instances
    )

    select
        bei.response_set_id,
        bei.entity_type_identifier,
        bei.entity_instance_id,
        -- Add " (entity_instance_id)" to name if not first occurence of name for this identifier.
        bei.name || case when bei.entity_instance_id = c.first_id_for_name then '' else ' (' || bei.entity_instance_id || ')' end as name,
        bei.enabled,
        bei.start_date
    from base_entity_instances bei
    inner join first_ids_for_names c
        on
            bei.response_set_id = c.response_set_id
            and bei.entity_type_identifier = c.entity_type_identifier
            and bei.name = c.name

    union distinct
    -- Add two fake choices for Is_Checked entity type
    select distinct
        et_cs_map.response_set_id,
        et_cs_map.entity_type_identifier,
        _checked_choices.entity_instance_id,
        _checked_choices.name,
        true as enabled,
        null as start_date
    from impl_response_set._entity_type_alternative_choice_set_mappings et_cs_map
    cross join impl_response_set._checked_choices
    where et_cs_map.entity_type_identifier = 'Is_Checked'

);


-- Deploying: schemas\impl_response_set\tables\entity_types.sql
create or replace transient dynamic table impl_response_set.entity_types (
    response_set_id integer,
    identifier varchar(256),
    display_name_singular varchar(256),
    display_name_plural varchar(256),
    original_choice_set_names array
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    with mapped_choice_sets as (
        select distinct
            m.response_set_id,
            first_value(m.canonical_choice_set_id)
                over (partition by m.response_set_id, m.entity_type_identifier order by m.canonical_choice_set_id)
                as canonical_choice_set_id,
            first_value(m.entity_type_identifier)
                over (partition by m.response_set_id, m.entity_type_identifier order by m.canonical_choice_set_id)
                as entity_type_identifier,
            array_agg(distinct ccs.name)
                over (partition by m.response_set_id, m.entity_type_identifier)
                as original_choice_set_names
        -- This filters out ones with no question variable, but ideally we would use the choice set name in that case
        from impl_response_set._entity_type_alternative_choice_set_mappings m
        inner join impl_response_set_unconfigured.canonical_choice_sets ccs
            on
                m.response_set_id = ccs.response_set_id
                and m.canonical_choice_set_id = ccs.canonical_choice_set_id
    )

    -- Finally, apply any human configuration overrides for display names based on the mapped_choice_sets identifier
    select
        mcs.response_set_id,
        mcs.entity_type_identifier as identifier,
        coalesce(cfg.display_name_singular, mcs.entity_type_identifier) as display_name_singular,
        coalesce(cfg.display_name_plural, mcs.entity_type_identifier || 's') as display_name_plural,
        mcs.original_choice_set_names
    from mapped_choice_sets mcs
    left join impl_response_set._entity_type_configurations cfg
        on
            cfg.response_set_id = mcs.response_set_id
            and cfg.identifier = mcs.entity_type_identifier
);


-- Deploying: schemas\impl_response_set\tables\_variable_question_mapping.sql

create or replace transient dynamic table impl_response_set._variable_question_mapping
cluster by (response_set_id, question_id) -- Premature optimization: For join to answers
target_lag = 'downstream' warehouse = warehouse_xsmall refresh_mode = incremental
as (
    select
        qvm.response_set_id,
        qvm.variable_identifier,
        cqm.alternative_question_id as question_id
    from impl_response_set._variable_canonical_question_mappings qvm
    join
        impl_response_set_unconfigured.canonical_question_alternative_mappings cqm
        on
            qvm.response_set_id = cqm.response_set_id
            and qvm.canonical_question_id = cqm.canonical_question_id
);


-- Deploying: schemas\client_all__response_set\views\entity_instances.sql
create or replace secure view client_all__response_set.entity_instances (
    entity_type_identifier,
    entity_instance_id,
    name,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select
        ei.entity_type_identifier,
        ei.entity_instance_id,
        ei.name,
        rs.response_set_descriptor,
        rs.response_set_id
    from impl_response_set.entity_instances as ei
    inner join client_all__response_set.response_sets as rs
        on ei.response_set_id = rs.response_set_id
    where ei.enabled = true
);


-- Deploying: schemas\client_all__response_set\views\entity_types.sql
create or replace secure view client_all__response_set.entity_types (
    entity_type_identifier,
    display_name_singular,
    display_name_plural,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select
        et.identifier as entity_type_identifier,
        et.display_name_singular,
        et.display_name_plural,
        rs.response_set_descriptor,
        rs.response_set_id
    from impl_response_set.entity_types as et
    inner join client_all__response_set.response_sets as rs
        on et.response_set_id = rs.response_set_id
);


-- Deploying: schemas\impl_response_set\tables\_question_variable_answers.sql
create or replace transient dynamic table impl_response_set._question_variable_answers (
    response_set_id integer,
    response_id integer,
    variable_identifier varchar(256),
    asked_entity_id_1 integer,
    asked_entity_id_2 integer,
    asked_entity_id_3 integer,
    answer_value integer,
    answer_text varchar(4000)
) cluster by (trunc(response_set_id, -1)) -- Premature optimization: Cluster roughly by response_set_id since almost always operating within a single response_set
target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    select
        q.response_set_id,
        a.response_id,
        q.variable_identifier,
        coalesce(a.section_choice_id, a.page_choice_id, a.question_choice_id) as asked_entity_id_1,
        -- PERF: Optimization of: array_construct_compact(a.section_choice_id, a.page_choice_id, a.question_choice_id)[1]
        case
            when a.section_choice_id is not null then coalesce(a.page_choice_id, a.question_choice_id)
            when a.page_choice_id is not null then a.question_choice_id
            else null
        end as asked_entity_id_2,
        -- PERF: Optimization of: array_construct_compact(a.section_choice_id, a.page_choice_id, a.question_choice_id)[2]
        case
            when a.section_choice_id is not null and a.page_choice_id is not null then a.question_choice_id
            else null
        end as asked_entity_id_3,
        coalesce(a.answer_choice_id, a.answer_value) as answer_value,
        -- TODO: Consider parsing floats at this stage into the numeric column
        a.answer_text
    from raw_survey.answers a
    inner join impl_response_set.responses r on a.response_id = r.response_id
    inner join impl_response_set._variable_question_mapping q on r.response_set_id = q.response_set_id and a.question_id = q.question_id
    where r.answers_enabled
);
/*
-- Add response sets one by one:

insert into raw.response_set_answers_enabled (response_set_id) values (76), (80);

alter dynamic table impl_response_set._question_variable_answers  refresh;

-- WIP
create or replace procedure impl_response_set.process_response_sets(response_set_ids array)
returns string
language sql
as
declare
    i integer := 0;
    id integer;
    n integer := array_size(:response_set_ids);
begin
    while i < n do
        id := :response_set_ids[i];
        insert into raw.response_set_answers_enabled (response_set_id) values (id);
        alter dynamic table impl_response_set._question_variable_answers refresh;
        i := i + 1;
    end while;
    return 'Processed ' || n || ' response sets.';
end;

 */


-- Deploying: schemas\impl_response_set\tables\variable_answers.sql
create or replace transient dynamic table impl_response_set.variable_answers (
    response_set_id integer,
    response_id integer,
    variable_identifier varchar(256),
    asked_entity_id_1 integer,
    asked_entity_id_2 integer,
    asked_entity_id_3 integer,
    answer_value integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
(
    -- For now just pulls question variable answers...at some point will union in derived variable answers
    select
        response_set_id,
        response_id,
        variable_identifier,
        asked_entity_id_1,
        asked_entity_id_2,
        asked_entity_id_3,
        answer_value
    from impl_response_set._question_variable_answers
);


-- Deploying: schemas\impl_weight\tables\_spike_response_with_components_of_cell_id.sql
-- response_with_components_of_cell_id: builds cell components for each response
create or replace transient dynamic table impl_weight._spike_response_with_components_of_cell_id (
    response_set_id integer,
    response_id integer,
    component_of_cell_id float,
    cell_part_id integer not null,
    cell_part integer not null,
    date_survey_completed date
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
select
    va.response_set_id,
    va.response_id,
    pow(255, cell_part)
    * cd.cell_part_id as component_of_cell_id,
    cd.cell_part_id,
    cd.cell_part,
    r.survey_completed as date_survey_completed
from impl_response_set.responses r
inner join impl_response_set.variable_answers as va on r.response_id = va.response_id
inner join impl_weight._hardcoded_response_set_cell_definitions as cd on va.response_set_id = cd.response_set_id and va.variable_identifier = cd.variable_identifier
where answer_value between cd.min_value and cd.max_value;


-- Deploying: schemas\impl_response_set\tables\dynamic_table_refresh_controller.sql

create or replace dynamic table impl_response_set.dynamic_table_refresh_controller
target_lag = 'downstream' warehouse = warehouse_xsmall refresh_mode = incremental
as
-- Add any leaf tables here. Then to refresh all upstream:
-- alter dynamic table impl_response_set.dynamic_table_refresh_controller refresh;
select 'variables' as table_name, count(*) as row_count from impl_response_set.variables
union all
select 'entity_types' as table_name, count(*) as row_count from impl_response_set.entity_types
union all
select 'entity_instances' as table_name, count(*) as row_count from impl_response_set.entity_instances
union all
select 'variable_answers' as table_name, count(*) as row_count from impl_response_set.variable_answers;


-- Deploying: schemas\client_all__response_set\views\variable_answers.sql
create or replace secure view client_all__response_set.variable_answers (
    response_id,
    variable_identifier,
    asked_entity_id_1,
    asked_entity_id_2,
    asked_entity_id_3,
    answer_value,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    select
        va.response_id,
        va.variable_identifier,
        va.asked_entity_id_1,
        va.asked_entity_id_2,
        va.asked_entity_id_3,
        -- This special case is depended upon internally, but we don't want to expose it externally
        case
            when v.question_is_multiple_choice and va.answer_value = -99 then 0 else
                va.answer_value
        end as answer_value,
        rs.response_set_descriptor,
        rs.response_set_id
    from impl_response_set.variable_answers as va
    inner join impl_response_set.variables as v
        on
            va.variable_identifier = v.variable_identifier
            and va.response_set_id = v.response_set_id
    inner join client_all__response_set.response_sets as rs
        on va.response_set_id = rs.response_set_id
    where
        v.variable_configuration_id is not null -- Only show configured variables for now at least
        and v.response_set_id in (76) -- Spike: eatingout uk

);


-- Deploying: schemas\impl_weight\tables\cell_responses.sql
create or replace transient dynamic table impl_weight.cell_responses (
    response_set_id integer,
    root_weighting_plan_id integer,
    cell_id float,
    response_id integer,
    date_survey_completed date
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
select
    cvm.response_set_id,
    cvm.root_weighting_plan_id, -- Can possibly have multiple weighting plans within a response set?
    cvm.cell_id,
    r.response_id,
    -- These will all be identical within the group
    max(r.survey_completed) as date_survey_completed
    --max(cvm.target_weight) as target_weight --could add for convenience if needed?
from impl_weight._cell_variable_mappings cvm
inner join impl_response_set.variable_answers va
    on
        va.response_set_id = cvm.response_set_id
        and va.variable_identifier ilike cvm.variable_identifier
        -- Only supports single choice variables
        and va.answer_value = cvm.entity_instance_id
inner join impl_response_set.responses r on r.response_set_id = va.response_set_id and r.response_id = va.response_id
where r.response_set_id != 80 -- SPIKE: Hard code eatingout US below
group by cvm.response_set_id, cvm.root_weighting_plan_id, cvm.cell_id, r.response_id
having count(cvm.cell_id) = max(cvm.num_required_parts) and count(distinct cvm.cell_id) = max(cvm.num_required_parts)

union all -- SPIKE: Hardcode eatingout US until we have calculated variables available

select response_set_id, 0 as root_weighting_plan_id, sum(rc.component_of_cell_id) as cell_id, response_id, date_survey_completed
from impl_weight._spike_response_with_components_of_cell_id rc
where response_set_id = 80
group by response_id, response_set_id, date_survey_completed
having count(cell_part) = 4 and count(distinct cell_part) = 4;


-- Deploying: schemas\client_all__response_set\views\denormalized_variable_answers.sql
create or replace secure view client_all__response_set.denormalized_variable_answers (
    variable_identifier,
    response_id,
    survey_completed,
    asked_entity_type_identifier_1,
    asked_instance_name_1,
    asked_entity_type_identifier_2,
    asked_instance_name_2,
    asked_entity_type_identifier_3,
    asked_instance_name_3,
    answer_entity_type_identifier,
    answer,
    answer_value,
    long_text,
    response_set_descriptor,
    response_set_id
) row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id) as
(
    -- This is an easy way for humans to explore the data.
    -- Most use cases don't need the text joining and will be faster without it.
    select
        v.variable_identifier,
        va.response_id,
        r.survey_completed,
        asked_entity_type_identifier_1,
        asked_instances_1.name as asked_instance_name_1,
        asked_entity_type_identifier_2,
        asked_instances_2.name as asked_instance_name_2,
        asked_entity_type_identifier_3,
        asked_instances_3.name as asked_instance_name_3,
        v.answer_entity_type_identifier,
        answer_i.name as answer,
        va.answer_value,
        v.long_text,
        r.response_set_descriptor,
        r.response_set_id
    from client_all__response_set.variable_answers va
    join client_all__response_set.variables v
        on
            v.response_set_descriptor = va.response_set_descriptor
            and v.variable_identifier = va.variable_identifier
    join client_all__response_set.responses r
        on
            va.response_set_descriptor = r.response_set_descriptor
            and va.response_id = r.response_id
    left join client_all__response_set.entity_instances answer_i
        on
            answer_i.response_set_descriptor = r.response_set_descriptor
            and answer_i.entity_type_identifier = v.answer_entity_type_identifier
            and answer_i.entity_instance_id = va.answer_value
    left join client_all__response_set.entity_instances asked_instances_1
        on
            asked_instances_1.response_set_descriptor = r.response_set_descriptor
            and asked_instances_1.entity_type_identifier = v.asked_entity_type_identifier_1
            and asked_instances_1.entity_instance_id = va.asked_entity_id_1
    left join client_all__response_set.entity_instances asked_instances_2
        on
            asked_instances_2.response_set_descriptor = r.response_set_descriptor
            and asked_instances_2.entity_type_identifier = v.asked_entity_type_identifier_2
            and asked_instances_2.entity_instance_id = va.asked_entity_id_2
    left join client_all__response_set.entity_instances asked_instances_3
        on
            asked_instances_3.response_set_descriptor = r.response_set_descriptor
            and asked_instances_3.entity_type_identifier = v.asked_entity_type_identifier_3
            and asked_instances_3.entity_instance_id = va.asked_entity_id_3
);


-- Deploying: schemas\impl_weight\tables\daily_cell_counts.sql
create or replace transient dynamic table impl_weight.daily_cell_counts (
    end_day date,
    cell_id float,
    respondents_on_day number(18, 0),
    response_set_id integer
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
select date_survey_completed as end_day, cell_id, count(*) as respondents_on_day, rc.response_set_id
from impl_result.dates d
left outer join impl_weight.cell_responses rc on rc.response_set_id = d.response_set_id and rc.date_survey_completed = d.the_date
group by date_survey_completed, cell_id, rc.response_set_id;


-- Deploying: schemas\impl_result\tables\running_daily_cell_counts.sql
create or replace transient dynamic table impl_result.running_daily_cell_counts (
    response_set_id integer,
    end_day date,
    cell_id integer,
    respondents_up_to_day number(30, 0),
    target_up_to_day number(38, 10)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
select
    tw.response_set_id,
    d.the_date as end_day,
    tw.cell_id,
    sum(coalesce(dc.respondents_on_day, 0))
        over (
            partition by d.response_set_id, tw.cell_id order by d.the_date
        ) as respondents_up_to_day,
    tw.target_weight * sum(coalesce(dc.respondents_on_day, 0))
        over (
            partition by d.response_set_id order by d.the_date
        ) as target_up_to_day
from impl_result.dates d
inner join impl_weight.target_weights tw on d.response_set_id = tw.response_set_id
left join impl_weight.daily_cell_counts dc on d.the_date = dc.end_day and tw.cell_id = dc.cell_id and d.response_set_id = dc.response_set_id;


-- Deploying: schemas\impl_result\tables\monthly_weighted_results.sql
create or replace transient dynamic table impl_result.monthly_weighted_results (
    response_set_id integer,
    end_day date,
    variable_identifier varchar(256),
    asked_entity_id_1 integer,
    asked_entity_id_2 integer,
    asked_entity_id_3 integer,
    answer_value integer,
    weighted_answer_value_sum number(38, 12),
    weighted_sample_size number(38, 12),
    unweighted_sample_size number(18, 0)
    -- Could cluster by (response_set_id, variable_identifier, end_day)
) target_lag = 'DOWNSTREAM' refresh_mode = incremental initialize = on_create warehouse = warehouse_xsmall
as
with monthly_weight_multipliers as (
    select
        end_day_counts.response_set_id,
        end_day_counts.end_day,
        end_day_counts.cell_id,
        (
            (end_day_counts.target_up_to_day - coalesce(before_start_day_counts.target_up_to_day, 0))
            / (end_day_counts.respondents_up_to_day - coalesce(before_start_day_counts.respondents_up_to_day, 0))
        )
            as weight_multiplier
    from impl_result.running_daily_cell_counts end_day_counts
    left join impl_result.running_daily_cell_counts before_start_day_counts on
        end_day_counts.cell_id = before_start_day_counts.cell_id
        and before_start_day_counts.end_day = last_day(dateadd(month, -1, end_day_counts.end_day))
)

--takes 1 minute to create for eatingout us+uk with no clustering
select
    va.response_set_id,
    mwm.end_day,
    va.variable_identifier,
    va.asked_entity_id_1,
    va.asked_entity_id_2,
    va.asked_entity_id_3,
    va.answer_value,
    sum(
        case
            when v.question_is_multiple_choice = true and va.answer_value = -99 then 0
            when v.answer_entity_type_identifier is not null then 1
            else va.answer_value
        end * mwm.weight_multiplier
    ) as weighted_answer_value_sum,
    sum(mwm.weight_multiplier) as weighted_sample_size,
    count(*) as unweighted_sample_size
from impl_response_set.variable_answers as va
inner join impl_weight.cell_responses r
    on
        r.response_set_id = va.response_set_id
        and r.response_id = va.response_id
inner join impl_response_set.variables as v
    on
        v.response_set_id = va.response_set_id
        and v.variable_identifier = va.variable_identifier
inner join monthly_weight_multipliers mwm
    on
        va.response_set_id = mwm.response_set_id
        and last_day(r.date_survey_completed) = mwm.end_day
        and r.cell_id = mwm.cell_id
group by va.response_set_id, mwm.end_day, va.variable_identifier, va.asked_entity_id_1, va.asked_entity_id_2, va.asked_entity_id_3, va.answer_value;


-- Deploying: schemas\impl_result\views\weight_multipliers_for_period.sql
create or replace view impl_result.weight_multipliers_for_period (
    response_set_id,
    day_before_start,
    end_day,
    cell_id,
    weight_multiplier_for_period
) as
-- Example calculates weight multipliers for a 14-day period
select
    end_day_counts.response_set_id, before_start_day_counts.end_day as day_before_start, end_day_counts.end_day, end_day_counts.cell_id,
    (end_day_counts.target_up_to_day - before_start_day_counts.target_up_to_day) / (end_day_counts.respondents_up_to_day - before_start_day_counts.respondents_up_to_day) as weight_multiplier_for_period
from impl_result.running_daily_cell_counts end_day_counts
left join impl_result.running_daily_cell_counts before_start_day_counts on
    end_day_counts.cell_id = before_start_day_counts.cell_id
    and before_start_day_counts.end_day = dateadd(day, -14 - 1, end_day_counts.end_day);


-- Deploying: schemas\client_all__response_set\views\monthly_weighted_results.sql

create or replace secure view client_all__response_set.monthly_weighted_results
row access policy impl_response_set.readable_response_set_for_role_policy on (response_set_id)
as
select
    mwr.end_day,
    mwr.variable_identifier,
    mwr.asked_entity_id_1,
    mwr.asked_entity_id_2,
    mwr.asked_entity_id_3,
    mwr.answer_value,
    mwr.weighted_answer_value_sum,
    mwr.weighted_sample_size,
    mwr.unweighted_sample_size,
    rs.response_set_descriptor,
    rs.response_set_id
from impl_result.monthly_weighted_results as mwr
inner join client_all__response_set.response_sets as rs
    on mwr.response_set_id = rs.response_set_id
;

create or replace function savanta_internal__utils.email_to_snake_name(email varchar)
returns varchar
language sql
as
$$
begin
    return upper(replace(split_part(:email, '@', 1), '.', '_'));
end;
$$;


create or replace procedure savanta_internal__utils.create_proxy_views(
    source_schema_ish varchar(500),
    target_qualified_schema varchar(500),
    replace_existing boolean default false
)
returns varchar
language sql
as
$$
declare
    source_database varchar default current_database(); -- i.e. db that contains the sproc
    optional_or_replace varchar default case when :replace_existing then ' or replace' else '' end;
    create_view_sql varchar;
    execution_result varchar default '';
    row_count integer default 0;
    table_resultset resultset;
    no_tables_or_views_found_exception exception (-20001, 'No tables or views found matching the specified criteria');
begin
    table_resultset := (
        select table_name, table_type, table_schema
        from information_schema.tables
        where table_catalog = upper(:source_database)
          and table_schema ilike :source_schema_ish
          and table_type in ('BASE TABLE', 'VIEW')
    );
    
    -- Use FOR loop with RESULTSET
    for record in table_resultset do
        row_count := row_count + 1;
        
        create_view_sql := 'create' || optional_or_replace || ' view ' || :target_qualified_schema || '.' || record.table_name || 
                          ' as select * from ' || :source_database || '.' || record.table_schema || '.' || record.table_name;
        
        execute immediate create_view_sql;
        
        execution_result := execution_result || '\ncreated proxy view ' || :target_qualified_schema || '.' || record.table_name || 
                           ' for ' || record.table_type || ' ' || :source_database || '.' || record.table_schema || '.' || record.table_name;
    end for;
    
    -- Error if no rows found
    if (row_count = 0) then
        raise no_tables_or_views_found_exception;
    end if;

    return 'Created ' || row_count || ' proxy views:' || execution_result;
end;
$$;

create or replace procedure savanta_internal__utils.clone_full(
    user_to_create_for varchar default current_user(),
    source_db_name varchar default current_database(),
    target_db_name varchar(500) default null,
    replace_existing boolean default false
)
returns varchar
language sql
execute as caller
as
$$
-- execute as caller above ensures caller has the right to take ownership of the database - and potentially bypass things like row level security.
-- See create_proxy_views for a safe way to create views in the cloned database for a specific user.
declare
    execution_result varchar default '';
    snake_user_name varchar;
    user_role varchar;
    db_owner_role varchar;
begin
    snake_user_name := savanta_internal__utils.email_to_snake_name(:user_to_create_for);
    target_db_name := coalesce(:target_db_name, 'DEV_' || snake_user_name || '__VUE__' || replace(current_date(), '-', '_'));
    user_role := snake_user_name || '__U_ROLE';
    db_owner_role := target_db_name || '__OWNER__D_ROLE';
    if (replace_existing) then
        drop database if exists identifier(:target_db_name);
    end if;

    create role if not exists identifier(:db_owner_role);
    grant role identifier(:db_owner_role) to role identifier(:user_role);

    create database if not exists identifier(:target_db_name) clone identifier(:source_db_name);

    grant ownership on database identifier(:target_db_name) to role identifier(:db_owner_role) revoke current grants;
    grant ownership on all schemas in database identifier(:target_db_name) to role identifier(:db_owner_role) revoke current grants;
    grant all on database identifier(:target_db_name) to role identifier(:db_owner_role);
    grant all on all schemas in database identifier(:target_db_name) to role identifier(:db_owner_role);
    grant all on future schemas in database identifier(:target_db_name) to role identifier(:db_owner_role);
    grant all on all tables in database identifier(:target_db_name) to role identifier(:db_owner_role);
    grant all on future tables in database identifier(:target_db_name) to role identifier(:db_owner_role);

    execution_result := 'Database ' || :target_db_name || ' cloned successfully from ' || :source_db_name || ' for role ' || :db_owner_role || '.';
    return execution_result;
end;
$$;


create or replace function savanta_internal__utils.py_format(f_string varchar, params variant)
returns varchar
language python
runtime_version = '3.11'
handler = 'format_string'
as
$$
def format_string(f_string, params):
    return f_string.format(**params)
$$;
